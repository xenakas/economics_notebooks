{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Модели с дискретными объясняемыми переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    1. Модели бинарного выбора \n",
    "\n",
    "##### Классическая линейная модель:\n",
    "\n",
    "$$y_i = \\theta_1 x_{i1} + ... + \\theta_p x_{ip} + u_i$$\n",
    "\n",
    "\n",
    "Попытка оценить такую модель МНК наталкивается на определенные трудности: \n",
    "\n",
    "При обычном предположении:\n",
    "$$ E(y_i | х_i) = x_i^T \\theta $$\n",
    "\n",
    "\n",
    "В то же время, поскольку $y_i$  принимает только значения — 0 и 1, ее условное математическое ожидание (при заданном\n",
    "значении х,) равно:\n",
    "\n",
    "$$ E(y_i | х_i)   =   Р \\{ у_i  = 1| х_i  \\} $$  \n",
    "\n",
    "\n",
    "Таким образом $$ x_i^T \\theta =  Р \\{ у_i  = 1| х_i  \\} $$ - вероятность, а значит, она должна быть в рамках $[0,1]$ \n",
    "\n",
    "$$Var(\\epsilon_i|x_i) = x_i^T\\theta(1-x_i^T\\theta)$$\n",
    "\n",
    "Также возникает проблема гетероскедастичности,\n",
    "осложненная еще и тем, что в выражения для дисперсий\n",
    "входит (неизвестный) вектор параметров $\\theta$.\n",
    "\n",
    "\n",
    "Коэффициент $\\theta$ практически всегда   является неинтерпретируемым. \n",
    "\n",
    "\n",
    "##### Логит-, пробит-, гомпит-модели\n",
    "\n",
    "\n",
    "$$ у_i = G(\\theta_1 x_{i1} + ... + \\theta_p x_{ip} ) + u_i =  G(x_{i}^T \\theta) + u_i $$\n",
    "\n",
    "\n",
    "Предположим, что при фиксированных значениях объясняющих переменных, случайные ошибки статистически независимы, так что функция правдоподобия параметров имеет вид:\n",
    "\n",
    "$$ L(\\theta|x) = \\prod  (G(x_{i}^T \\theta))^{y_i} (1- G(x_{i}^T \\theta))^{1 - y_i} $$\n",
    "\n",
    "\n",
    "Максимизируя логарифмическую функцию правдоподобия, получаем оценки $\\hat{\\theta}$. \n",
    "\n",
    "\n",
    "- Пробит-модель - функция стандартного нормального распределения\n",
    "\n",
    "$$\\Phi (z) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{z} e^{-t^2/2}dt  $$\n",
    "\n",
    "- Логит-модель - функция стандартного логистического распределения\n",
    "\n",
    "$$\\Lambda (z) = \\frac{e^z}{1+e^z}$$\n",
    "\n",
    "- Гомпит-модель - функция стандартного распределения экстремальных значений (минимума) I типа (распределение Гомпертца)\n",
    "\n",
    "$$ G(z) = 1 -exp(-e^z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    2. Показатели качества моделей бинарного выбора\n",
    "\n",
    "\n",
    "Поскольку теперь имеем дело с нелинейными моделями, мы не можем пользоваться обычным коэффициентом детерминации $R^2$. \n",
    "\n",
    "\n",
    "Одна из имеющихся возможностей в этом отношении — сравнение количеств неправильных предсказаний, получаемых по выбранной модели и по\n",
    "модели, в которой в качестве единственной объясняющей переменной выступает константа (тривиальная модель).\n",
    "\n",
    "$$R^2_{predict} = 1 - \\frac{v_{wrong,1}}{v_{wrong,0}} = 1 - \\frac{\\sum (y_i-\\hat{y}_i)^2}{v_{wrong,0}}$$\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*} v_{wrong,0} = \n",
    " \\begin{cases}\n",
    "   1- \\bar{y} &\\text{если $\\bar{y} >1/2$}\\\\\n",
    "   \\bar{y} &\\text{если $\\bar{y} \\leq 1/2$}\n",
    " \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Проблема, однако, в том, что выбранная модель может дать предсказание\n",
    "хуже, чем тривиальная,  тогда $R^2$. \n",
    "\n",
    "Отметим\n",
    "также, что вообще тривиальная модель может неправильно предсказать не более половины наблюдений,  поэтому эта доля может быть большой и для плохой модели.\n",
    "\n",
    "Поскольку для оценивания моделей бинарного выбора мы использовали метод максимального правдоподобия, то естественным представляется сравнение максимумов функций правдоподобия (или максимумов логарифмических функций правдоподобия) для выбранной и тривиальной моделей.\n",
    "\n",
    "$$pseudo R^2 = 1 - \\frac{1}{1+ \\frac{2(\\ln L_1 - \\ln L_0 )}{n}} $$\n",
    "\n",
    "\n",
    "$$LRI = McFadden R^2 = 1 - \\frac{\\ln L_1 }{\\ln L_0} $$\n",
    "\n",
    "\n",
    "$L_1 $ — максимум функции правдоподобия для выбранной модели,\n",
    "$L_0 $  — максимум функции правдоподобия для тривиальной модели. Заметим, что $ L_0 \\leq L_1 < 1$, так что $ \\ln L_0  \\leq \\ln L_1 < 0 $ \n",
    "\n",
    "\n",
    "##### Cравнение альтернативных моделей.\n",
    "\n",
    "\n",
    "Как и в случае обычных линейных моделей, сравнивать качество нескольких альтернативных моделей бинарного выбора с разным количеством объясняющих переменных можно, опираясь на значения информационных критериев Акаике (AIC) и Шварца (BIC), Хеннана — Куинна:\n",
    "\n",
    "\n",
    "$$АIС = -\\frac{2\\ln L_k}{n} + \\frac{2p}{n}, BIC = -\\frac{2\\ln L_k}{n} + \\frac{p \\ln n}{n} , HQ = -\\frac{2\\ln L_k}{n} + \\frac{2p \\ln(\\ln n )}{n}$$\n",
    "\n",
    "##### Критерии согласия с имеющимися данными\n",
    "\n",
    "Критерий Хосмера — Лемешоу: \n",
    "\n",
    "критерий основан на сравнении количеств предсказываемых\n",
    "моделью и действительно наблюдаемых случаев с  $у_i  = 1$  в нескольких группах, на которые разбивается множество наблюдений.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    3. Интерпретация коэффициентов\n",
    "\n",
    "Поскольку модели логит, пробит и гомпит являются нелинейными, оцененные коэффициенты в этих моделях имеют интерпретацию, отличающуюся\n",
    "от интерпретации коэффициентов в линейной модели.\n",
    "\n",
    "\n",
    "Пусть $k$-я объясняющая переменная является непрерывной переменной.\n",
    "Тогда предельный эффект (marginal effect) этой переменной определяется\n",
    "как производная:\n",
    "\n",
    "$$\\frac{\\partial P\\{ y_i = 1| x_i\\}}{\\partial x_{ik}} = \\frac{\\partial G (x_i^T \\theta )}{\\partial x_{ik}}$$\n",
    "\n",
    "и в отличие от линейной модели этот эффект зависит от значений объясняющих переменных для $i$-го субъекта. \n",
    "\n",
    "\n",
    "$$\\Delta P\\{ y_i = 1| x_i\\}  = \\frac{\\partial P\\{ y_i = 1| x_i\\}}{\\partial x_{ik}} \\Delta x_{ik} = \\frac{\\partial G (x_i^T \\theta )}{\\partial x_{ik}} \\Delta x_{ik}$$\n",
    "\n",
    "В случае когда сама объясняющая переменная - дамми-переменная, предельный эффект определяют просто как разность\n",
    "\n",
    "$$\\Delta P\\{ y_i = 1| x_i, d_i=1\\} - \\Delta P\\{ y_i = 1| x_i, d_i=0\\} $$\n",
    "\n",
    "\n",
    "\n",
    "Пусть $р$ — вероятность некоторого события. Отношение шансов $\\frac{p}{1-p}$\n",
    "\n",
    "\n",
    "Логарифм отношения шансов называют логитом: $logit(р) = \\ln  \\frac{p}{1-p}$ \n",
    "\n",
    "\n",
    "Если  $logit(p) > 0$, то больше шансов, что событие А произойдет. Если $logit(p) < 0$, то больше шансов, что событие А не произойдет.\n",
    "\n",
    "\n",
    "Логит-модель линейна в отношении логита. Отсюда вытекает, что изменение значения $k$-й объясняющей переменной на величину $\\Delta x_{ik}$ приводит (при неизменных значениях остальных объясняющих переменных) к изменению значения логита на $\\theta_k \\Delta x_{ik} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    4. Проверка выполнения стандартных предположений\n",
    "\n",
    "\n",
    "$$P\\{ y_i = 1| x_i\\}  = \\Phi (x_i^T \\theta  + \\omega_1 (x_i^T \\theta )^2 + \\omega_2 (x_i^T \\theta )^3) $$\n",
    "\n",
    "$H_0:   \\omega_1 =  \\omega_2 =0 $ \n",
    "\n",
    "Критерий отношения правдоподобий (LR test) -  отвергает гипотезу, если наблюдаемое значение статистики LR превышает критическое значение. Этот критерий асимптотический: критическое значение вычисляется на основе распределения, к которому стремится при $n\\to \\infty$  распределение статистики LR, если гипотеза $H_0$ верна. Этим предельным распределением является распределение хи-квадрат с двумя степенями свободы.\n",
    "\n",
    "\n",
    "$$LR = -2 \\ln \\frac{L_1}{L_2}  $$\n",
    "\n",
    "\n",
    "Итак, в соответствии с критерием отношения правдоподобий гипотеза $Н_0$\n",
    "отвергается, если\n",
    "\n",
    "$$LR > \\chi^2_{1-\\alpha}(2)  $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Еще одним «стандартным предположением» является предположение об\n",
    "одинаковом распределении случайных ошибок. В сочетании с предположением нормальности этих ошибок данное условие сводится к совпадению дисперсий всех этих ошибок.\n",
    "\n",
    "Нарушение\n",
    "этого условия приводит к гетероскедастичной модели и к несостоятельности\n",
    "оценок максимального правдоподобия, получаемых на основании стандартной модели. \n",
    "\n",
    "Для проверки гипотезы совпадения дисперсий можно опять рассмотреть какую-нибудь более общую модель с наличием гетероскедастичности, частным случаем которой является стандартная пробит-модель.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    5. Порядковая пробит-модель\n",
    "\n",
    "\n",
    "$$y_i^* = \\beta_1 x_{i1} + ... + \\beta_p x_{ip} + u_i$$\n",
    "\n",
    "\n",
    "\\begin{equation*} y_i = \n",
    " \\begin{cases}\n",
    "   1 &\\text{если $y^*_i \\leq \\gamma_{i1}$ }\\\\\n",
    "   ... \\\\\n",
    "   k &\\text{если $  \\gamma_{i,k-1} < y^*_i \\leq \\gamma_{i,k}$ }\\\\\n",
    "   ... \\\\\n",
    "   K &\\text{если $  y^*_i \\geq \\gamma_{i,K-1} $}\\\\\n",
    "  \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Предполагая, что ошибки независимые в совокупности  случайные величины, имеющие одинаковое нормальное распределение, получаем порядковую пробит-модель.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    6. Мультиномиальная модель\n",
    "\n",
    "В целом ряде случаев не существует естественного упорядочения альтернатив, благодаря которому и возникает монотонная связь между непрерывной латентной переменной и наблюдаемой переменной, принимающей конечное количество значений.\n",
    "\n",
    "\n",
    "Пусть имеем К таких альтернатив (занумеруем их в произвольном порядке) и пусть $i$-й субъект исследования приписывает $k$-й альтернативе полезность $u_{ik}$, так что\n",
    "\n",
    "\n",
    "$$u_{ik}  = \\beta_1 x_{i1,k} + ... + \\beta_p x_{ip, k} + u_{ik} = x^T_{ik}\\beta + u_{ik}$$\n",
    "\n",
    "\n",
    "Предположим, что i-й субъект выбирает альтернативу к , если для него эта альтернатива имеет максимальную полезность. Тогда  вероятность того, что $i$-й субъект выберет альтернативу $u_{ik}$:\n",
    " \n",
    "\n",
    "$$P\\{ y_i = k \\}  = P\\{ u_{ik} = \\max_{j} u_{ij} \\}   = P \\{ x^T_{ik}\\beta + u_{ik} > \\max_{j} (x^T_{ij}\\beta + u_{ij} ) \\} $$\n",
    "\n",
    "\n",
    "Выразить такую вероятность в явном виде весьма проблематично. Однако\n",
    "если предположить, что общим для всех случайных величин  является\n",
    "Гампит распределение (это распределение часто называют также распределением Гумбеля), то формула для вычисления вероятности\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$ P\\{y_i = k\\} = \\frac{\\exp(x^T_{ik}\\beta )}{\\exp(x^T_{i1}\\beta ) + ... + \\exp(x^T_{iK}\\beta )} $$\n",
    "\n",
    "\n",
    "\n",
    "Естественная нормализация, при которой полагают $x^T_{i1}\\beta = 0$: \n",
    "\n",
    "\n",
    "\n",
    "$$ P\\{y_i = k\\} = \\frac{\\exp(x^T_{ik}\\beta )}{1+ \\exp(x^T_{i2}\\beta ) + ... + \\exp(x^T_{iK}\\beta )} $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    7.Стандартная тобит-модель\n",
    "\n",
    "\n",
    "$$y_i^* = \\theta_1 x_{i1} + ... + \\theta_p x_{ip} + u_i$$\n",
    "\n",
    "\n",
    "Наблюдаемыми являются значения:\n",
    "\n",
    "\n",
    "\\begin{equation*} y_i = \n",
    " \\begin{cases}\n",
    "   y_i^* &\\text{если $y^*_i > 0 $ }\\\\\n",
    "   0 &\\text{если $  y^*_i \\leq   0  $}\\\\\n",
    "  \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "В нашем примере значение коэффициента $\\theta_j$  определяет изменение ожидаемой суммы расходов на (возможную) покупку автомобиля для семьи с вектором показателей $x_i$  при увеличении на единицу значения $j$-го показателя.\n",
    "\n",
    "\n",
    "Если для оценивания коэффициентов $\\theta_j$ использовать только наблюдения с $у_i > 0$, получим усеченную модель регрессии (truncated regression):\n",
    "\n",
    "\n",
    "$$y_i = \\theta_1 x_{i1} + ... + \\theta_p x_{ip} + u_i$$\n",
    "\n",
    "\n",
    "В такой модели для значений $w > 0$ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    8. Cтандартная тобит-II модель\n",
    "\n",
    "Модель Тобина имеет один недостаток. Дело в том, что значение $y=0$ может означать выбор «не участвовать», а значения $y>0$, можно интерпретировать как «интенсивность участия». В тобит-модели и выбор «участвовать-не участвовать» и «интенсивность участия» определяются одними и теми же факторами и факторы действуют в одном направлении. \n",
    "\n",
    "Классический пример фактора и ситуации неоднозначного влияния — количество детей как фактор, влияющий на расходы семьи. Очевидно, что большое количество детей может негативно влиять на решение «отдыхать или нет» (из-за больших расходов), однако, если принято такое решение, то величина расходов (\"интенсивность участия) на отдых прямо зависит от количества детей.\n",
    "\n",
    "Хекман предложил разделить модель на две составляющие — модель бинарного выбора для участия, и линейную модель для интенсивности участия и факторы этих двух моделей вообще говоря могут быть разными.\n",
    "\n",
    "Таким образом, в модели Хекмана имеются две латентные переменные, удовлетворяющие следующим моделям:\n",
    "\n",
    "$$ y_i^{*}=x_{1i}^{T} \\theta_1 + u_{1i} $$\n",
    "\n",
    "\n",
    "$$ h_i^{*}=x_{2i}^{T} \\theta_2 + u_{2i} $$\n",
    "\n",
    "\n",
    "Случайные составляющие $u_{1i},  u_{2i}$  могут быть коррелированными\n",
    "\n",
    "\n",
    "\n",
    "Вторая латентная переменная определяет выбор «участвовать/не участвовать» в рамках стандартной модели бинарного выбора (например, пробит-модели):\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*} h_i = \n",
    " \\begin{cases}\n",
    "   1 &\\text{если $h^*_i > 0 $ }\\\\\n",
    "   0 &\\text{если $  h^*_i \\leq   0  $}\\\\\n",
    "  \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Первая модель — это модель интенсивности участия при условии выбора «участвовать». Если выбирается «не участвовать», то y не наблюдается (равна нулю).\n",
    "\n",
    "\n",
    "\\begin{equation*} y_i = \n",
    " \\begin{cases}\n",
    "   y_i^* &\\text{если $h_i = 1 $ }\\\\\n",
    "   0 &\\text{если $  h_i = 0 $}\\\\\n",
    "  \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "Если $u_{1i}, u_{2i}$ не коррелированы между собой, то можно, игнорируя уравнение для $h^*_i$, производить непосредственное оценивание уравнения регрессии   обычным МНК. Это приводит к состоятельным оценкам, но  если $\\sigma_{12}^ \\neq 0$, то при таком оценивании возникает смещение оценки $х^T_{1i} \\theta_1$ пропорциональное величине, которую называют лямбдой Хекмана.\n",
    "\n",
    "\n",
    "Получить состоятельные и асимптотически эффективные оценки параметров модели тобит-II можно, используя метод ML,\n",
    "при котором соответствующая функция правдоподобия максимизируется по\n",
    "всем возможным значениям параметров модели $\\theta_1, \\theta_2, \\sigma_1, \\sigma_2$. \n",
    "\n",
    "\n",
    "\n",
    "Оценка модели Хекмана производится также методом максимального правдоподобия, однако в связи с нестандартностью данной задачи часто применяют упрощенную двухшаговую процедуру оценивания, предложенную Хекманом. \n",
    "\n",
    "\n",
    "##### Двухшаговая процедура Хекмана:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "На первом шаге оценивается модель бинарного выбора и определяются параметры этой модели.\n",
    "Оценивание вектора $\\theta_2$ производится в рамках пробит-модели бинарного\n",
    "выбора. \n",
    "\n",
    "На полученных параметров можно определить для каждого наблюдения лямбду Хекмана: $ \\hat{\\lambda}_i =\\lambda(х^T_{2i} \\hat{\\theta_2}) $ \n",
    "\n",
    "\n",
    "\n",
    "Идея Хекмана состоит в использовании соотношения\n",
    "\n",
    "$$ E \\{ y_i | h_i=1\\} = х^T_{1i} \\theta_1 + \\sigma_{12} \\lambda(х^T_{2i} \\theta_2) $$\n",
    "\n",
    "\n",
    "где $\\lambda_i = \\lambda(х^T_{2i} \\theta_2) =  \\frac{\\phi(\\lambda(х^T_{2i} \\theta_2))}{\\Phi (\\lambda(х^T_{2i} \\theta_2))} $\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "На втором шаге обычным МНК оценивается регрессия\n",
    "\n",
    "\n",
    "$$ y_i^{*}=x_{1i}^{T} \\theta_1 +  \\sigma_{12} \\lambda_i  + v_{1i} $$\n",
    "\n",
    "\n",
    "Полученные оценки являются неэффективными, но вполне могут быть использованы в качестве начальных значений для итерационной процедуры максимизации функции правдоподобия.\n",
    "\n",
    "\n",
    "\n",
    "Заметим, что в стандартной тобит-II модели функция правдоподобия имеет вид:\n",
    "\n",
    "$ L (\\theta_1, \\theta_2, \\sigma_1, \\sigma_12)  = \\prod (P\\{h_i = 0\\})^{(1-h_i)}  ( P\\{h_i = 1\\} f(y_i | h_i=1))^{h_i}$\n",
    "\n",
    "где $f(y_i | h_i=1)$ — условная плотность распределения случайной величины $y_i$ при $h_i = 1$.\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R 4.0.2",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
